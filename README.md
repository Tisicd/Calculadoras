# SolvMath - Calculadora Matem√°tica Avanzada

Una calculadora web completa que combina **MathJS**, **SymPy** y **LLM local** para proporcionar c√°lculos matem√°ticos con explicaciones paso a paso.

## üöÄ Caracter√≠sticas

### Calculadora de Matrices
- ‚úÖ C√°lculo de matrices inversas paso a paso
- ‚úÖ M√∫ltiples m√©todos: Gauss-Jordan, Adjunta/Cofactores, F√≥rmula 2x2
- ‚úÖ Visualizaci√≥n con MathJax
- ‚úÖ Soporte para matrices 2x2, 3x3 y NxN

### Calculadora de Funciones
- ‚úÖ Evaluaci√≥n de funciones en puntos espec√≠ficos
- ‚úÖ Derivadas simb√≥licas
- ‚úÖ Integrales (definidas e indefinidas)
- ‚úÖ Simplificaci√≥n de expresiones
- ‚úÖ Paso a paso detallado con SymPy
- ‚úÖ Verificaci√≥n num√©rica con MathJS

### Explicaciones Inteligentes
- ‚úÖ Integraci√≥n con LLM local (Ollama/LocalAI)
- ‚úÖ Explicaciones en lenguaje natural
- ‚úÖ Fallback autom√°tico cuando LLM no est√° disponible

## üèóÔ∏è Arquitectura

```
Frontend (Vanilla JS + TailwindCSS)
‚îú‚îÄ‚îÄ MathJS (c√°lculos inmediatos)
‚îú‚îÄ‚îÄ SymPy Backend (c√°lculos simb√≥licos)
‚îî‚îÄ‚îÄ LLM Local (explicaciones naturales)
```

### Stack Tecnol√≥gico

**Frontend:**
- HTML5 + CSS3 + JavaScript ES6+
- TailwindCSS para estilos
- MathJax para renderizado matem√°tico
- MathJS para c√°lculos num√©ricos

**Backend:**
- Python 3.8+
- FastAPI para API REST
- SymPy para √°lgebra simb√≥lica
- Uvicorn como servidor ASGI

**LLM (Opcional):**
- Ollama o LocalAI
- Modelos: Mistral, CodeLlama, etc.

## üìã Requisitos

### Sistema
- Python 3.8 o superior
- Navegador web moderno
- 2GB RAM m√≠nimo
- 1GB espacio en disco

### Opcional (para LLM)
- Docker (para Ollama)
- 4GB+ RAM (para modelos medianos)
- GPU compatible (recomendado)

## üõ†Ô∏è Instalaci√≥n

### 1. Clonar el repositorio
```bash
git clone <repository-url>
cd calculadoras
```

### 2. Iniciar el backend
```bash
# Opci√≥n 1: Script autom√°tico
python start_backend.py

# Opci√≥n 2: Manual
cd backend
pip install -r requirements.txt
python functions_service.py
```

### 3. Iniciar el frontend
```bash
# Servir archivos est√°ticos
python -m http.server 8001

# O usar cualquier servidor web est√°tico
```

### 4. Configurar LLM (Opcional)
```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Descargar modelo
ollama pull mistral:7b

# Iniciar servicio
ollama serve
```

## üê≥ Docker (Recomendado)

### Backend con Docker
```bash
cd backend
docker-compose up --build
```

### Con Docker Compose completo
```yaml
version: '3.8'
services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  ollama_data:
```

## üìñ Uso

### 1. Acceder a la aplicaci√≥n
Abre `http://localhost:8001` en tu navegador

### 2. Calculadora de Matrices
- Selecciona "Matriz Inversa" en el men√∫ lateral
- Elige el tama√±o de la matriz (2x2, 3x3, etc.)
- Completa los valores
- Presiona "Calcular pasos previos"
- Selecciona el m√©todo de resoluci√≥n

### 3. Calculadora de Funciones
- Selecciona "C√°lculo" en el men√∫ lateral
- Ingresa una funci√≥n (ej: `x^2 + 2*x + 1`)
- Elige la operaci√≥n (evaluar, derivar, integrar, simplificar)
- Presiona "Calcular"
- Revisa los pasos detallados y la explicaci√≥n

## üîß Configuraci√≥n

### Backend (SymPy)
```python
# backend/functions_service.py
app = FastAPI(
    title="Calculadora de Funciones API",
    description="API para c√°lculos simb√≥licos con SymPy"
)
```

### LLM (Ollama)
```javascript
// calculators/explainWithLLM.js
const llmExplainer = new LLMExplainer({
  llmUrl: 'http://localhost:11434',
  model: 'mistral:7b'
});
```

## üìù Ejemplos de Funciones

### Polinomios
```
x^2 + 2*x + 1
3*x^3 - 2*x^2 + x - 5
x^4 - 16
```

### Trigonom√©tricas
```
sin(x)
cos(x)^2
sin(x)*cos(x)
tan(x)
```

### Exponenciales
```
exp(x)
2^x
x*exp(x)
exp(-x^2)
```

### Logar√≠tmicas
```
log(x)
x*log(x)
log(x^2 + 1)
```

### Racionales
```
1/(x^2 + 1)
x/(x^2 - 4)
(x^2 + 1)/(x - 1)
```

## üß™ Testing

### Backend
```bash
cd backend
python -m pytest tests/
```

### Frontend
```bash
# Abrir DevTools y ejecutar tests
npm test  # Si se configura package.json
```

## üêõ Soluci√≥n de Problemas

### Backend no inicia
- Verificar que Python 3.8+ est√© instalado
- Revisar que todas las dependencias est√©n instaladas
- Comprobar que el puerto 8000 est√© libre

### Frontend no se conecta
- Verificar que el backend est√© ejecut√°ndose
- Comprobar CORS en el navegador
- Revisar la consola del navegador

### LLM no funciona
- Verificar que Ollama est√© instalado y ejecut√°ndose
- Comprobar que el modelo est√© descargado
- Revisar logs de Ollama

## üìä API Endpoints

### Health Check
```http
GET /health
```

### Evaluar funci√≥n
```http
POST /function/evaluate
{
  "function": "x^2 + 2*x + 1",
  "operation": "evaluate",
  "value": 2
}
```

### Derivar funci√≥n
```http
POST /function/derive
{
  "function": "x^2 + 2*x + 1",
  "operation": "derive"
}
```

### Integrar funci√≥n
```http
POST /function/integrate
{
  "function": "x^2 + 2*x + 1",
  "operation": "integrate"
}
```

### Simplificar funci√≥n
```http
POST /function/simplify
{
  "function": "(x^2 + 2*x + 1)/(x + 1)",
  "operation": "simplify"
}
```

## ü§ù Contribuir

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia ISC. Ver el archivo `LICENSE` para m√°s detalles.

## üôè Agradecimientos

- [SymPy](https://www.sympy.org/) - Biblioteca de matem√°ticas simb√≥licas
- [FastAPI](https://fastapi.tiangolo.com/) - Framework web moderno
- [MathJS](https://mathjs.org/) - Biblioteca de matem√°ticas para JavaScript
- [TailwindCSS](https://tailwindcss.com/) - Framework CSS utilitario
- [Ollama](https://ollama.ai/) - Herramienta para ejecutar LLMs localmente

## üìû Soporte

Si tienes problemas o preguntas:
1. Revisa la secci√≥n de [Soluci√≥n de Problemas](#-soluci√≥n-de-problemas)
2. Busca en los [Issues](https://github.com/tu-usuario/calculadoras/issues)
3. Crea un nuevo issue si no encuentras soluci√≥n

---

**Desarrollado con ‚ù§Ô∏è para la educaci√≥n matem√°tica**

